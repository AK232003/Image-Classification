{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag Of Visual Words Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pylab as pl\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    bdir = './Content/Bikes/'\n",
    "    hdir = './Content/Horses/'\n",
    "    \n",
    "    img_paths_horse = []\n",
    "    img_paths_bike = []\n",
    "    img_paths = []\n",
    "\n",
    "    for i in os.listdir(hdir):\n",
    "        img_paths_horse.append(os.path.join(hdir, i))\n",
    "\n",
    "    for i in os.listdir(bdir):\n",
    "        img_paths_bike.append(os.path.join(bdir, i))\n",
    "\n",
    "    img_paths = img_paths_bike + img_paths_horse\n",
    "\n",
    "    img_class0 = [0]*len(img_paths_bike)\n",
    "    img_class1 = [1]*len(img_paths_horse)\n",
    "\n",
    "    img_class = img_class0 + img_class1\n",
    "\n",
    "    return img_paths, img_class\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(img_paths, img_class):\n",
    "    random.seed(23)\n",
    "    train_imgs_paths, test_imgs_paths, train_labels, test_labels = train_test_split(img_paths, img_class, train_size=0.8, random_state=42,shuffle = True, stratify = img_class)\n",
    "\n",
    "    return train_imgs_paths, test_imgs_paths, train_labels, test_labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resizing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_imgs(l):\n",
    "    imgs = []\n",
    "\n",
    "    for i in l:\n",
    "        img = cv2.imread(i)\n",
    "        img = cv2.resize(img,(275,180))\n",
    "        imgs.append(img)\n",
    "\n",
    "    imgs = np.asarray(imgs)\n",
    "    return imgs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting descriptors of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_descriptors(imgs):\n",
    "    extractor = cv2.SIFT_create()\n",
    "    descriptors = np.asarray([])\n",
    "\n",
    "    for img in imgs:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        kps, descs = extractor.detectAndCompute(gray, None)\n",
    "        if type(descs) == np.ndarray :\n",
    "            if descriptors.shape[0] == 0:\n",
    "                descriptors = descs\n",
    "            else:\n",
    "                descriptors = np.concatenate((descriptors, descs), axis=0)\n",
    "\n",
    "    return descriptors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Vocabulary using K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(descriptors):\n",
    "    kmeans = KMeans(n_clusters = 512)\n",
    "    kmeans.fit(descriptors)\n",
    "\n",
    "    return kmeans"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing Histograms/Bag Of Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_histograms(imgs, words, nClusters):\n",
    "    histograms = []\n",
    "    extractor = cv2.SIFT_create()\n",
    "    for img in imgs:\n",
    "        histogram = [0]*nClusters\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        kps, descs = extractor.detectAndCompute(gray, None)\n",
    "\n",
    "        if(type(descs) == np.ndarray):\n",
    "            prediction = words.predict(descs)\n",
    "            for i in prediction:\n",
    "                histogram[i] = histogram[i] + 1\n",
    "        \n",
    "        histograms.append(histogram)\n",
    "\n",
    "    return np.asarray(histograms)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(features, train_labels):\n",
    "    model = svm.SVC(C = 0.005, kernel = 'linear')\n",
    "    model.fit(features, train_labels)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths, img_class = load_data()\n",
    "train_imgs_paths, test_imgs_paths, train_labels, test_labels = train_test(img_paths, img_class)\n",
    "\n",
    "train_imgs = resize_imgs(train_imgs_paths)\n",
    "descriptors = get_descriptors(train_imgs)\n",
    "words = get_words(descriptors)\n",
    "features = build_histograms(train_imgs, words, nClusters = 512)\n",
    "\n",
    "model = train(features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9722222222222222"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_imgs = resize_imgs(test_imgs_paths)\n",
    "test_features = build_histograms(test_imgs, words, nClusters = 512)\n",
    "accuracy = model.score(test_features, test_labels)\n",
    "accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train1(features, train_labels):\n",
    "    model1 = LogisticRegression(max_iter = 1000)\n",
    "    model1.fit(features, train_labels)\n",
    "\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9722222222222222"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = train1(features, train_labels)\n",
    "\n",
    "accuracy1 = model1.score(test_features, test_labels)\n",
    "accuracy1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train2(features, train_labels):\n",
    "    model2 = KNeighborsClassifier(n_neighbors = 5)\n",
    "    model2.fit(features, train_labels)\n",
    "\n",
    "    return model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9166666666666666"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = train2(features, train_labels)\n",
    "\n",
    "accuracy2 = model2.score(test_features, test_labels)\n",
    "accuracy2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
